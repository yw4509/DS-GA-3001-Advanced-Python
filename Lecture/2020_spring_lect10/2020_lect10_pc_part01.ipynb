{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 10\n",
    "\n",
    "## Python Parallel Computing - Part 01\n",
    "\n",
    "### Apr 07, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of this lecture is based on the previous years lectures and the material [parallel computing](https://nyu-cds.github.io/python-mpi/01-introduction/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You will need **mpi4py** \n",
    "\n",
    "To install: [https://mpi4py.readthedocs.io/en/stable/install.html](https://mpi4py.readthedocs.io/en/stable/install.html)\n",
    "\n",
    "\n",
    "Run the following in terminal: \n",
    "\n",
    "1. sudo apt install libopenmpi-dev\n",
    "\n",
    "2. pip install mpi4py\n",
    "\n",
    "\n",
    "or \n",
    "\n",
    "1. brew install open-mpi\n",
    "\n",
    "2. pip3 install mpi4py\n",
    "\n",
    "\n",
    "If errors, see this article for further details: [https://stackoverflow.com/questions/28440834/error-when-installing-mpi4py](https://stackoverflow.com/questions/28440834/error-when-installing-mpi4py)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two basic approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs/shared_memory.png\" alt=\"shared_memory\" style=\"width: 350px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs/distributed_memory.png\" alt=\"distributed_memory\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __MPI__ (Message Passing Interface) \n",
    "\n",
    "- Most widely used standard\n",
    "\n",
    "\n",
    "- For programming distributed-memory multiple instruction--multiple data (MIMD) systems\n",
    "\n",
    "\n",
    "#### __Point to point Communication__\n",
    "\n",
    "Processes should coordinate their activities by explicitly sending and receiving messages\n",
    "\n",
    "MPI operates as follows:\n",
    "- Process A decides a message needs to be sent to process B.\n",
    "- Process A packs up all of its necessary data into a buffer for process B.\n",
    "- Process A indicates that the data should be sent to process B by calling the _Send_ function.\n",
    "- Process B needs to acknowledge it wants to receive the message by calling the _Recv_ function.\n",
    "\n",
    "Every time a process sends a message, there must be a process that also indicates it wants to receive the message, therefore, calls to _Send_ and _Recv_ are always paired.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./figs/send_receive.png\" alt=\"distributed_memory\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The number of processes \n",
    "\n",
    "- Is **fixed** when an MPI program is started \n",
    "- Message Passing Interface (MPI)\n",
    "\n",
    "- Each of the processes is assigned a unique integer starting from 0. \n",
    "\n",
    "- This integer is know as the rank of the process and is how each process is identified when sending and receiving messages (we will refer to rank K process as \"process K\").\n",
    "\n",
    "- **MPI processes** are arranged in logical collections known as **communicators**. \n",
    "\n",
    "- There is one special communicator (**MPI.COMM_WORLD**) that exists when an MPI program starts, which contains all the processes in the MPI program. \n",
    "\n",
    "\n",
    "- MPI provides a few **methods** on a communicator:\n",
    "\n",
    "\n",
    "> Get_size() - returns the total number of processes contained in the communicator (the size of the communicator).\n",
    "\n",
    "> Get_rank() - returns the rank of the calling process within the communicator. \n",
    "\n",
    "> Send() - sends content to a process\n",
    "\n",
    "> Recv() - receives content from a process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank() #like address\n",
    "print('hello world: size = %d, rank = %d' % (size, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi1.py\n",
    "#####\n",
    "# writting the code in the mpi1.py file\n",
    "#####\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "print('hello world: size = %d, rank = %d' % (size, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# running MPI from the terminal with n=4 processes\n",
    "#####\n",
    "!mpiexec -n 14 python3 mpi1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### One MPI program, multiple MPI processes\n",
    "Making each process to perform a different computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi2.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "a = 8.0\n",
    "b = 4.0\n",
    "print('Process rank',rank)\n",
    "if rank == 0:\n",
    "        print(\"addition:\", a + b)\n",
    "if rank == 1:\n",
    "        print(\"multiplication:\", a * b)\n",
    "if rank == 2:\n",
    "        print(\"maximum:\", max(a,b))\n",
    "if rank == 3:\n",
    "        print(\"doing nothing:\")\n",
    "        \n",
    "        \n",
    "# the order depends on the rank, unless we filter on rank order, likw if the rank order is 1234 we do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 4 python3 mpi2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Point-to-point communication\n",
    "Message passing involves two processes: a **sender** and a **receiver** (commands _Send_ and _Recv_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi3.py\n",
    "#####\n",
    "# Sending a message from one process to another\n",
    "#####\n",
    "import numpy\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        # generates a numpy array with one element unif. distr. from [0,1)\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"part of Process\", rank, \"- drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"part of Process\", rank, \"- before receiving has the number\", randNum[0])\n",
    "        #before receiving, what's in my buffer\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print(\"part of Process\", rank, \"- received the number\", randNum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi3.py\n",
    "#we are waiting all thigns to finish, thus 0 print before 1\n",
    "#all of it is blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi4.py\n",
    "#####\n",
    "# Sending a message to a process and receiving a message back\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "        comm.Recv(randNum, source=0)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from process 0\")\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from process 1\")\n",
    "        randNum *= 2\n",
    "        comm.Send(randNum, dest=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs/send_receive_mul2.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The receiving process does not always need to specify the source when issuing a Recv. Instead, the process can accept **any message** that is being sent by another process. This is done by setting the source to **MPI.ANY_SOURCE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi5.py\n",
    "#####\n",
    "# Sending a message to a process and receiving a message back from MPI.ANY_SOURCE\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from process\", MPI.ANY_SOURCE)\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])    \n",
    "        randNum *= 2\n",
    "        comm.Send(randNum, dest=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Sometimes there are cases when a process might have to **send many different types of messages to another process**. Instead of having to go through extra measures to differentiate all these messages, MPI allows senders and receivers to also **specify message IDs (known as tags)** with the message. The receiving process can then request a message with a certain tag number and messages with different tags will be buffered until the process requests them.\n",
    "\n",
    "```python\n",
    "Comm.Send(buf, dest=0, tag=0)\n",
    "Comm.Recv(buf, source=0, tag=0, status=None)\n",
    "```\n",
    "\n",
    "The _status_ can provide useful information\n",
    "```python\n",
    "info = MPI.Status()\n",
    "source = info.Get_source()\n",
    "tag = info.Get_tag()\n",
    "count = info.Get_elements()\n",
    "size = info.Get_count()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi_tag.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank() \n",
    "\n",
    "data1 = None\n",
    "data2 = None\n",
    "\n",
    "if rank == 0:\n",
    "    data1 = ('a','b', 'c', 'd')\n",
    "    data2 = (1, 2, 3, 4)\n",
    "    comm.send(data1, dest=1, tag=100)\n",
    "    comm.send(data2, dest=1, tag=200)\n",
    "\n",
    "elif rank == 1:\n",
    "    print('On Process',rank,'before recv: data1 = ', data1)\n",
    "    print('On Process',rank,'before recv: data2 = ', data2)\n",
    "    \n",
    "    data1 = comm.recv(source=0, tag=100)\n",
    "    data2 = comm.recv(source=0, tag=200)\n",
    "    \n",
    "    print('On Process',rank,'after  recv: data1 = ', data1)\n",
    "    print('On Process',rank,'after  recv: data2 = ', data2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi_tag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi_status.py\n",
    "#####\n",
    "# Sending a message from one process to another\n",
    "#####\n",
    "\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "info = MPI.Status()\n",
    "# print(\"info: \", info)\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "\n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=1, status=info)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from Process\", info.Get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi_status.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Non-blocking Communication\n",
    "\n",
    "In the previous examples, the sender and receiver are not able to perform any action when sending or receiving a message, wasting computational times while waiting for the call to complete. \n",
    "\n",
    "__Non-blocking communcation__ avoids this issue by using the _Isend_ and _Irecv_ methods, which start to send and receive operations and _then return immediately to continue computation_.\n",
    "\n",
    "The completion of a send or receive operation can be managed using the _Test_, _Wait_, and _Cancel_ methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi6.py\n",
    "#####\n",
    "# this code is similar to mpi3.py, \n",
    "# but it uses Wait to block the processes\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        \n",
    "        req = comm.Isend(randNum, dest=0)\n",
    "        req.Wait()\n",
    "        \n",
    "        print('something here')\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        \n",
    "        req = comm.Irecv(randNum, source=1)\n",
    "#         req.Wait() #wait till i received from 1\n",
    "        \n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap communication\n",
    "\n",
    "\n",
    "**Example:** Process 1 overlaps a computation with sending the message and receiving the reply. The computation divides randNum by 10 and prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi7.py\n",
    "#####\n",
    "# overlap communication\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Isend(randNum, dest=0)\n",
    "        randNum[0] /= 10 # overlap communication\n",
    "        print(\"Process\", rank, \"number in overlap communication =\", randNum[0])\n",
    "        req = comm.Irecv(randNum, source=0)\n",
    "        req.Wait()\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])\n",
    "\n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        req = comm.Irecv(randNum, source=1)\n",
    "        req.Wait()\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])\n",
    "        randNum *= 2\n",
    "        comm.Isend(randNum, dest=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python3 mpi7.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
